"""
This file contains the Parser class implementation.
"""
from domain.utils.tokenizer import Token, TokenType, Tokenizer
from test.entities.content_exception import ContentException


class Parser:
    """
    This class represents a parser.
    This step takes the sequence of tokens built in step 1 and checks that the sequence meets
    the syntactical rules of regular arithmetic expressions. If there are no errors,
    the output of this process is the same sequence of tokens generated by the tokenizer.
    """

    def __init__(self):
        """
        This method initializes the parser.

        Attributes:
        tokens -- the list of tokens (list)
        current_token -- the current token (Token)
        token_index -- the current token index (int)
        """
        self._tokens = []
        self.current_token = None
        self.token_index = -1

    def clean(self):
        """
        This method cleans the parser.
        """
        self._tokens = []
        self.current_token = None
        self.token_index = -1

    @property
    def tokens(self):
        """
        Getter for the tokens.
        """
        return self._tokens

    @tokens.setter
    def tokens(self, token_list: list):
        """
        Setter for the tokens.
        This makes sure that the token list is not empty and that all the elements are tokens.

        Keyword arguments:
        token_list -- the list of tokens (list)
        """
        if len(token_list) == 0:
            raise ContentException("Empty formula")
        for item in token_list:
            if not isinstance(item, Token):
                raise ContentException("Invalid token")
        self._tokens = token_list
        self.advance()

    def advance(self):
        """
        Advance the current token index and set the current token.
        """
        self.token_index += 1
        if self.token_index < len(self.tokens):
            self.current_token = self.tokens[self.token_index]
        else:
            self.current_token = None

    def parse(self, token_list: list):
        """
        Parse the list of tokens and check the syntactical rules.
        If there are no errors, return the same list of tokens.

        Returns:
        tokens -- the list of tokens (list)
        """
        self.clean()
        self.tokens = token_list  # Set the token list
        self.expression()
        return self.tokens

    def expression(self):
        """
        This method checks the syntactical rules of the expression.
        expression -> term { ( '+' | '-' ) term }
        """
        self.term()
        while self.current_token and self.current_token.value in ('+', '-'):
            self.advance()
            self.term()

    def term(self):
        """
        This method checks the syntactical rules of the term.
        term -> factor { ( '*' | '/' ) factor }
        """
        self.factor()
        while self.current_token and self.current_token.value in ('*', '/'):
            self.advance()
            self.factor()

    def factor(self):
        """
        This method checks the syntactical rules of the factor.
        factor -> NUMBER | '(' expression ')' | FUNCTION '(' expression ')' | CELL_IDENTIFIER
        """
        if self.current_token and self.current_token.type == TokenType.NUMBER:
            self.advance()
        elif self.current_token and self.current_token.type == TokenType.OPENING_PARENTHESIS:
            self.advance()
            self.expression()
            self.check_closing_parenthesis()
        elif self.current_token and self.current_token.type == TokenType.FUNCTION:  # Function synthax comprobation.
            self.advance()
            self.check_function()
        elif self.current_token and self.current_token.type == TokenType.CELL_IDENTIFIER:
            self.advance()
        else:
            raise ContentException("Invalid factor, expected number, opening parenthesis, function or cell identifier")

    def check_function(self):
        """
        This method checks the syntactical rules of the function.
        """
        # Opening parenthesis comprobation.
        self.check_opening_parenthesis()
        if self.is_argument():
            while self.current_token.type == TokenType.SEMICOLON:
                self.advance()
                self.is_argument()
        else:
            raise ContentException("Expected argument.")
        self.check_closing_parenthesis()

    def is_argument(self):
        """
        This method checks if the token is an argument.
        It also advances the token index if the token is an argument.
        Also does a recursive call to check_function if the token is a function.

        Keyword arguments:
        token_to_check -- the token to check (Token)
        return -- True if the token is an argument, False otherwise (bool)
        """
        if self.is_range():
            return True
        elif self.current_token.type == TokenType.CELL_IDENTIFIER:
            self.advance()
            return True
        elif self.current_token.type == TokenType.NUMBER:
            self.advance()
            return True
        elif self.current_token.type == TokenType.FUNCTION:
            self.advance()
            self.check_function()
            return True

    def is_range(self):
        """
        This method checks if the token is a range.
        It also advances the token index if the token is a range.

        Keyword arguments:
        token_to_check -- the token to check (Token)
        return -- True if the token is a range, False otherwise (bool)
        """
        if self.current_token.type == TokenType.CELL_IDENTIFIER:
            if self._tokens[self.token_index + 1].type == TokenType.COLON:
                if self._tokens[self.token_index + 2].type == TokenType.CELL_IDENTIFIER:
                    self.advance()  # Advance for cell identifier.
                    self.advance()  # Advance for colon.
                    self.advance()  # Advance for cell identifier.
                    return True
        return False

    def check_closing_parenthesis(self):
        if self.current_token and self.current_token.type == TokenType.CLOSING_PARENTHESIS:
            self.advance()
        else:
            raise ContentException("Expected closing parenthesis")

    def check_opening_parenthesis(self):
        if self.current_token and self.current_token.type == TokenType.OPENING_PARENTHESIS:
            self.advance()
        else:
            raise ContentException("Expected opening parenthesis")


# ======================================================================================================================
# Example usage:
if __name__ == "__main__":
    tokenizer = Tokenizer()
    parser = Parser()

    string_to_parse = "A1 + MAX(MIN(MAX(2;5);3);A1:B2) * (10 - 4)"
    tokens = list(tokenizer.tokenize(string_to_parse))
    result = parser.parse(tokens)
    for token in result:
        print(str(token.value))
    print("---------------")
    string_to_parse = "AB1 + PROMEDIO(A1:B2;D2;3;MIN(2;3;A1)) * (D3 - 4) / C3 * P0"
    tokens = list(tokenizer.tokenize(string_to_parse))
    result = parser.parse(tokens)
    for token in result:
        print(str(token.value))
